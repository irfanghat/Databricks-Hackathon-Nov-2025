{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b600d5a2-8849-40de-9b83-97e6941ef9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1\n",
    "- Install the `databricks-industrial-automation-suite` Python package.\n",
    "- _See documentation_: [PyPi](https://pypi.org/project/databricks-industrial-automation-suite/#description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad310ef-39bd-4969-94ed-4ae8525e7154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-industrial-automation-suite mlflow --quiet\n",
    "%pip install https://github.com/irfanghat/Databricks-Hackathon-Nov-2025/releases/download/v0.0.1/opcua_manufacturing_server-0.0.1-py3-none-any.whl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c51ef33-a045-48dd-81ed-bd14a46acc80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0890140-1f45-4414-8be3-dadef7c9db0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip list | grep databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d5cd33-460d-4d7a-b8e9-56e39ce1ba8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2\n",
    "- Setup a basic OPC UA Client.\n",
    "- We can:\n",
    "  * Connect to a remote OPC UA server via IP address (e.g. 132.65.41.78).\n",
    "  * Use a prebuilt simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3273d22-0c09-441c-a08e-dfd7db5ef35b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_industrial_automation_suite.integrations.opcua import OPCUAClient\n",
    "import asyncio\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f2e37f8-ebad-4b06-83a8-1cdcb8b3777f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Configure multiple OPC UA endpoints\n",
    "# -------------------------------------------\n",
    "\n",
    "dbutils.widgets.text(\"Endpoint\", \"localhost:4840\", \"OPC UA endpoint\")\n",
    "endpoint = dbutils.widgets.get(\"Endpoint\")\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7c07d78-6a97-42cc-ac01-89a0274d15be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# Specify the OPC UA server URL and optionally, the path to the certificate file\n",
    "# to connect to a remote or on-prem OPC UA Server.\n",
    "#\n",
    "# The following is an example that connects to a remote OPC UA Server without a certificate.\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "oc = OPCUAClient(server_url=f\"opc.tcp://{endpoint}/freeopcua/server/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc50529-812f-4900-b2d1-798f52303fbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- \n",
    "# We can also simulate an OPC UA Server locally.\n",
    "# Start the server by running: !opcua-manufacturing-server\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# !opcua-manufacturing-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1483c79b-6e57-43c7-b891-9206176e4bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Browsing OPC UA Nodes with Databricks Industrial Automation Suite\n",
    "\n",
    "This example demonstrates how to **connect to an OPC UA server** and **browse its nodes** using the `databricks_industrial_automation_suite`. This is a core capability in industrial automation, enabling you to **discover devices, sensors, and production equipment programmatically** from within Databricks.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "* Industrial plants generate **huge volumes of real-time data** from PLCs, sensors, and other devices.\n",
    "* Using OPC UA, a **standard industrial protocol**, you can easily integrate this data into **Databricks**, enabling analytics, predictive maintenance, and optimization.\n",
    "* Browsing nodes is the **first step** to understanding your plant's data structure before you start streaming, monitoring, or controlling devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b6bd32-8302-4526-8df2-5125111d2975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Connecting to a Server\n",
    "\n",
    "You can connect to a server with or without authentication. For **Testing** and **Prototyping**, a local test server works well:\n",
    "\n",
    "```python\n",
    "oc = OPCUAClient(server_url=\"opc.tcp://localhost:4840/freeopcua/server/\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "775e2e0c-87d1-4fc8-aa06-fe93494593d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Important**: For **secure** servers, you can provide `security_policy`, `message_security_mode`, `certificate_path`, and `private_key_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac87b89f-772d-4a4a-8eeb-a8640291f7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Browsing Nodes\n",
    "\n",
    "We can get **all nodes and their hierarchy**:\n",
    "\n",
    "* `nodes` is a **nested dictionary** representing the full node hierarchy.\n",
    "* Each node contains:\n",
    "\n",
    "  * `id`: OPC UA node identifier\n",
    "  * `browse_name`: Human-readable name\n",
    "  * `children`: List of child nodes (empty if leaf node)\n",
    "\n",
    "---\n",
    "\n",
    "## Sample Output\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"id\": \"i=87\",\n",
    "    \"browse_name\": \"QualifiedName(NamespaceIndex=0, Name='Views')\",\n",
    "    \"children\": []\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"i=85\",\n",
    "    \"browse_name\": \"QualifiedName(NamespaceIndex=0, Name='Objects')\",\n",
    "    \"children\": [\n",
    "      {\"id\": \"ns=4;i=1240\", \"browse_name\": \"Boilers\", \"children\": [...]}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd7f904-ed8f-4a63-8422-4d412f822214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The output shows the **structure of an industrial plant**: Boilers ‚Üí Individual Boiler ‚Üí Pipes ‚Üí Sensors. With this, you can **start building dashboards, analytics pipelines, or predictive maintenance models in Databricks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79546ee-e6e9-4a33-8756-fc8767bdda63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "# With a single call, we can map an entire industrial plant's sensor network. \n",
    "# We could scale this to multiple factories and integrating it with Databricks' ML workflows‚Äîreal-time insights \n",
    "# and Predictive Analytics become possible at enterprise scale.\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Secure OPC UA Connection (with Databricks UC Volumes)\n",
    "#\n",
    "# In this example, we use Unity Catalog Volumes to securely store and access client certificates.\n",
    "# This ensures our encryption keys and certificates are managed centrally under Databricks governance.\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Example UC volume paths\n",
    "# Note: Replace <catalog>, <schema>, and <volume> with your actual UC volume identifiers.\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Volume path structure: /Volumes/<catalog>/<schema>/<volume>/<file>\n",
    "# ----------------------------------------------------------------------------\n",
    "cert_path = \"/Volumes/industrial_automation/security/client_cert.pem\"\n",
    "key_path  = \"/Volumes/industrial_automation/security/client_key.pem\"\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Secure OPC UA client configuration\n",
    "#\n",
    "# oc = OPCUAClient(\n",
    "#     server_url=\"opc.tcp://opcua.demo-this.com:51210/UA/SampleServer\",\n",
    "#     security_policy=\"Basic256Sha256\",         # Strong encryption policy\n",
    "#     message_security_mode=\"SignAndEncrypt\",   # Ensures confidentiality + integrity\n",
    "#     certificate_path=cert_path,               # Certificate stored in UC volume\n",
    "#     private_key_path=key_path,                # Private key stored in UC volume\n",
    "# )\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# oc = OPCUAClient(server_url=f\"opc.tcp://{endpoint}/freeopcua/server/\")\n",
    "\n",
    "\n",
    "# async def main():\n",
    "#     await oc.connect()\n",
    "#     nodes = await oc.browse_all()\n",
    "#     print(nodes)\n",
    "\n",
    "\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa47f9ff-c797-4c84-8038-e5d7e09f8e43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Checking Security Policies in OPC UA\n",
    "\n",
    "In industrial automation, **security is critical**. OPC UA supports multiple **security policies and message security modes** to ensure safe communication between clients and servers. Using the `databricks_industrial_automation_suite`, you can inspect and configure these policies when connecting to OPC UA servers.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "* Industrial plants often transmit **sensitive operational data** (sensor readings, machine states).\n",
    "* Proper **encryption and authentication** prevent eavesdropping, tampering, or unauthorized control.\n",
    "* Databricks integration allows you to **safely ingest and analyze industrial data at scale** without compromising security.\n",
    "\n",
    "* `security_policy` ‚Üí Determines encryption algorithm and strength.\n",
    "* `message_security_mode` ‚Üí Controls whether messages are signed, encrypted, or both.\n",
    "* `certificate_path` & `private_key_path` ‚Üí Client credentials for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4dfe68b-210b-4f69-97b1-b474cf28d953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Evaluating Security Policies programmatically\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Secure OPC UA Connection (with Databricks UC Volumes)\n",
    "#\n",
    "# In this example, we use Unity Catalog Volumes to securely store and access client certificates.\n",
    "# This ensures our encryption keys and certificates are managed centrally under Databricks governance.\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Example UC volume paths\n",
    "# Note: Replace <catalog>, <schema>, and <volume> with your actual UC volume identifiers.\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Volume path structure: /Volumes/<catalog>/<schema>/<volume>/<file>\n",
    "# ----------------------------------------------------------------------------\n",
    "cert_path = \"/Volumes/industrial_automation/security/client_cert.pem\"\n",
    "key_path  = \"/Volumes/industrial_automation/security/client_key.pem\"\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Secure OPC UA client configuration\n",
    "#\n",
    "# oc = OPCUAClient(\n",
    "#     server_url=\"opc.tcp://opcua.demo-this.com:51210/UA/SampleServer\",\n",
    "#     security_policy=\"Basic256Sha256\",         # Strong encryption policy\n",
    "#     message_security_mode=\"SignAndEncrypt\",   # Ensures confidentiality + integrity\n",
    "#     certificate_path=cert_path,               # Certificate stored in UC volume\n",
    "#     private_key_path=key_path,                # Private key stored in UC volume\n",
    "# )\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "oc = OPCUAClient(server_url=f\"opc.tcp://{endpoint}/freeopcua/server/\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "async def main():\n",
    "    policies = await oc.get_security_policies()\n",
    "    df = pd.DataFrame({'available_opcua_server_security_policies': policies})\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    display(spark_df)\n",
    "    spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"opcua_security_policies\")\n",
    "\n",
    "await main()\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Sample Output\n",
    "#\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#None\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Basic256Sha256\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Basic256Sha256\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Basic256Sha256\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Aes128_Sha256_RsaOaep\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Aes256_Sha256_RsaPss\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Aes128_Sha256_RsaOaep\n",
    "# http://opcfoundation.org/UA/SecurityPolicy#Aes256_Sha256_RsaPss\n",
    "#\n",
    "# -------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0f31563-3ac6-4d9b-93a3-d72cc5db0850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM default.opcua_security_policies;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22909ba3-636f-4b6d-a6e1-d63f949acc39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "* In traditional factory environments, certificates often live on local machines or control systems ‚Äî less secure and hard to manage.\n",
    "* With **Unity Catalog Volumes**, we can:\n",
    "\n",
    "  * Store security artifacts centrally.\n",
    "  * Control access with fine-grained permissions.\n",
    "  * Audit all data movements and authentications.\n",
    "* It's the foundation for **secure, enterprise-grade industrial connectivity at scale**.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Setup\n",
    "\n",
    "In Databricks:\n",
    "\n",
    "1. Create a volume in Unity Catalog:\n",
    "\n",
    "   ```sql\n",
    "   CREATE VOLUME industrial_automation.security;\n",
    "   ```\n",
    "2. Upload your certificate and key:\n",
    "\n",
    "   ```bash\n",
    "   databricks fs cp client_cert.pem dbfs:/Volumes/industrial_automation/security/\n",
    "   databricks fs cp client_key.pem  dbfs:/Volumes/industrial_automation/security/\n",
    "   ```\n",
    "3. Then the code above will access them like regular files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed7310b-b9fb-4c0c-a0e4-7673d19b0ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Subscribing to OPC UA Nodes (Streaming PLC Data in Real Time)\n",
    "\n",
    "This example shows how to use the `databricks_industrial_automation_suite` to **subscribe to real-time OPC UA nodes** ‚Äî simulating streaming data from sensors, PLCs, or control systems in an industrial plant.\n",
    "\n",
    "By subscribing to node updates, Databricks can continuously ingest live telemetry into Delta tables or directly into MLflow pipelines for **predictive maintenance, anomaly detection, and process optimization**.\n",
    "\n",
    "---\n",
    "\n",
    "### Subscribing to Nodes\n",
    "\n",
    "You can subscribe to any number of OPC UA nodes ‚Äî for instance, temperature, pressure, and RPM sensors ‚Äî to stream live updates directly into your Databricks environment.\n",
    "\n",
    "```python\n",
    "async def main():\n",
    "    await oc.connect()\n",
    "\n",
    "    node_ids = [\n",
    "        \"ns=2;i=5\",  # Temperature\n",
    "        \"ns=2;i=6\",  # Pressure\n",
    "        \"ns=2;i=7\",  # RPM\n",
    "    ]\n",
    "\n",
    "    # Subscribe to multiple nodes at once\n",
    "    for node_id in node_ids:\n",
    "        await oc.subscribe_to_node(node_id)\n",
    "\n",
    "    # Stream incoming events (real-time sensor updates)\n",
    "    async for event in oc.stream():\n",
    "        print(event)  # Structured dicts with timestamp, value, and node info\n",
    "        \n",
    "\n",
    "await main()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example Event Payload\n",
    "\n",
    "Each event streamed back from the OPC UA server will look like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"timestamp\": \"2025-11-12T13:32:45.123Z\",\n",
    "    \"node_id\": \"ns=2;i=5\",\n",
    "    \"browse_name\": \"Temperature\",\n",
    "    \"value\": 88.4,\n",
    "    \"unit\": \"¬∞C\"\n",
    "}\n",
    "```\n",
    "\n",
    "This can easily be:\n",
    "\n",
    "* written to a **Delta table** for analytics,\n",
    "* **visualized in real-time dashboards**, or\n",
    "* **fed into Databricks ML pipelines** for model training or live inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "697b8379-ee9d-47da-937d-c94887e3f803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "We can then:\n",
    "\n",
    "* Log each event into a **Delta Live Table** to create an event stream.\n",
    "* Use **Databricks Auto Loader** or **Structured Streaming** to persist incoming events.\n",
    "* Add **MLflow** tracking for anomaly detection models that consume this stream.\n",
    "\n",
    "Resulting in a full industrial data pipeline from OPC ‚Üí Delta ‚Üí Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b235752f-cd10-4650-abab-d24e6fdeee70",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762982496342}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "oc = OPCUAClient(server_url=f\"opc.tcp://{endpoint}/freeopcua/server/\")\n",
    "\n",
    "MAX_ROWS = 100\n",
    "MAX_WAIT_SECONDS = 60\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Threshold definitions for each sensor (Warning & Critical)\n",
    "# ---------------------------------------------------------------------------\n",
    "THRESHOLDS = {\n",
    "    \"Pump2.Temperature\": {\"warning\": 65, \"critical\": 75, \"description\": \"Pump 2 overheating\"},\n",
    "    \"Pump2.Vibration\": {\"warning\": 4.5, \"critical\": 6.0, \"description\": \"Pump 2 excessive vibration\"},\n",
    "    \"Compressor.Temperature\": {\"warning\": 80, \"critical\": 90, \"description\": \"Compressor overheating\"},\n",
    "    \"Compressor.DischargePressure\": {\"warning\": 14, \"critical\": 18, \"description\": \"Compressor overpressure\"},\n",
    "    \"QualityControl.PassRate\": {\"warning\": 97, \"critical\": 95, \"direction\": \"below\", \"description\": \"Quality below target\"},\n",
    "    \"Energy.TotalPowerConsumption\": {\"warning\": 220, \"critical\": 250, \"description\": \"High energy usage\"},\n",
    "    \"Environmental.AmbientTemperature\": {\"warning\": 35, \"critical\": 40, \"description\": \"Ambient temperature high\"},\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Extract clean node name\n",
    "# ---------------------------------------------------------------------------\n",
    "def extract_node_name(browse_name):\n",
    "    \"\"\"Extract clean name from QualifiedName string\"\"\"\n",
    "    if not browse_name:\n",
    "        return \"Unknown\"\n",
    "    match = re.search(r\"Name='([^']+)'\", str(browse_name))\n",
    "    return match.group(1) if match else str(browse_name)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Detect anomaly level (Normal / Warning / Critical)\n",
    "# ---------------------------------------------------------------------------\n",
    "def check_threshold(name, value):\n",
    "    for k, t in THRESHOLDS.items():\n",
    "        if k.endswith(name):\n",
    "            direction = t.get(\"direction\", \"above\")\n",
    "            if direction == \"below\":\n",
    "                if value < t[\"critical\"]:\n",
    "                    return \"critical\", t[\"description\"]\n",
    "                elif value < t[\"warning\"]:\n",
    "                    return \"warning\", t[\"description\"]\n",
    "            else:\n",
    "                if value > t[\"critical\"]:\n",
    "                    return \"critical\", t[\"description\"]\n",
    "                elif value > t[\"warning\"]:\n",
    "                    return \"warning\", t[\"description\"]\n",
    "    return \"normal\", \"\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Predictive indicator based on short-term trend\n",
    "# ---------------------------------------------------------------------------\n",
    "def compute_trend_forecast(df, window=5):\n",
    "    \"\"\"Simple rolling linear forecast to predict if thresholds will be exceeded soon\"\"\"\n",
    "    forecasts = []\n",
    "    for name, group in df.groupby(\"name\"):\n",
    "        if len(group) < window:\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------\n",
    "        # Compute slope of last few readings\n",
    "        # -------------------------------------\n",
    "        x = np.arange(len(group[-window:]))\n",
    "        y = group[\"value\"].tail(window).values\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "\n",
    "        # -----------------------\n",
    "        # Estimate next value\n",
    "        # -----------------------\n",
    "        predicted = y[-1] + slope * 2  # short projection\n",
    "        forecasts.append({\"name\": name, \"predicted_next\": predicted})\n",
    "    return pd.DataFrame(forecasts)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    await oc.connect()\n",
    "    print(\"üîå Connected to OPC UA server.\")\n",
    "\n",
    "    node_ids = [\n",
    "        \"ns=2;i=44\",  # Pump2.Temperature\n",
    "        \"ns=2;i=45\",  # Pump2.Vibration\n",
    "        \"ns=2;i=48\",  # Compressor.Temperature\n",
    "        \"ns=2;i=47\",  # Compressor.DischargePressure\n",
    "        \"ns=2;i=52\",  # QualityControl.PassRate\n",
    "        \"ns=2;i=57\",  # Energy.TotalPowerConsumption\n",
    "        \"ns=2;i=63\",  # Environmental.AmbientTemperature\n",
    "    ]\n",
    "    for node_id in node_ids:\n",
    "        await oc.subscribe_to_node(node_id)\n",
    "\n",
    "    print(f\"üì° Subscribed to {len(node_ids)} nodes\")\n",
    "\n",
    "    data = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    async for event in oc.stream():\n",
    "        name = extract_node_name(event.get(\"browse_name\"))\n",
    "        value = event.get(\"value\")\n",
    "\n",
    "        severity, desc = check_threshold(name, value)\n",
    "\n",
    "        data.append({\n",
    "            \"timestamp\": event.get(\"timestamp\"),\n",
    "            \"node_id\": event.get(\"node_id\"),\n",
    "            \"name\": name,\n",
    "            \"value\": value,\n",
    "            \"severity\": severity,\n",
    "            \"description\": desc\n",
    "        })\n",
    "\n",
    "        if severity != \"normal\":\n",
    "            emoji = \"üî¥\" if severity == \"critical\" else \"üü°\"\n",
    "            print(f\"{emoji} {severity.upper()} ‚Äî {name}: {value:.2f} ({desc})\")\n",
    "\n",
    "        if len(data) >= MAX_ROWS or (time.time() - start_time > MAX_WAIT_SECONDS):\n",
    "            break\n",
    "\n",
    "    await oc.disconnect()\n",
    "    print(f\"üìä Collected {len(data)} rows in {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Add rolling predictions\n",
    "    # -----------------------------\n",
    "    forecast_df = compute_trend_forecast(df)\n",
    "    df = df.merge(forecast_df, on=\"name\", how=\"left\")\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Flag predicted threshold violations\n",
    "    # --------------------------------------\n",
    "    df[\"predicted_status\"] = df.apply(\n",
    "        lambda r: (\n",
    "            \"‚ö†Ô∏è predicted_warning\"\n",
    "            if THRESHOLDS.get(r[\"name\"], {}).get(\"warning\") and r.get(\"predicted_next\", 0) > THRESHOLDS[r[\"name\"]][\"warning\"]\n",
    "            else (\n",
    "                \"üö® predicted_critical\"\n",
    "                if THRESHOLDS.get(r[\"name\"], {}).get(\"critical\") and r.get(\"predicted_next\", 0) > THRESHOLDS[r[\"name\"]][\"critical\"]\n",
    "                else \"normal\"\n",
    "            )\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "try:\n",
    "    df = await asyncio.wait_for(main(), timeout=MAX_WAIT_SECONDS + 2)\n",
    "except asyncio.TimeoutError:\n",
    "    print(\"‚ö†Ô∏è Timeout\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n",
    "if not df.empty:\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"factory_telemetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3577a4-5a6e-48b1-b419-70e678c4de95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "\n",
    "SELECT\n",
    "  timestamp,\n",
    "  node_id,\n",
    "  name,\n",
    "  value,\n",
    "  severity,\n",
    "  description,\n",
    "  predicted_next,\n",
    "  predicted_status\n",
    "FROM default.factory_telemetry\n",
    "WHERE severity = 'critical';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eddb5f8-2645-42ae-9bb6-335e25141915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### MLFlow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3705cad0-e8ea-4cf0-98dd-46eba46bd30c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = spark.table(\"factory_telemetry\").toPandas()\n",
    "\n",
    "print(\"Available metrics:\", df[\"name\"].unique())\n",
    "\n",
    "metric = \"Temperature\"\n",
    "data = df[df[\"name\"] == metric].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "if len(data) < 10:\n",
    "    raise ValueError(f\"Not enough samples for {metric}: only {len(data)} rows\")\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# Lag features\n",
    "# ------------------------------------\n",
    "for lag in range(1, 6):\n",
    "    data[f\"lag_{lag}\"] = data[\"value\"].shift(lag)\n",
    "data = data.dropna()\n",
    "\n",
    "X = data[[f\"lag_{i}\" for i in range(1, 6)]]\n",
    "y = data[\"value\"]\n",
    "\n",
    "if len(X) < 2:\n",
    "    raise ValueError(f\"Not enough lagged samples for {metric}: {len(X)} rows\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "# ------------------------------------\n",
    "# Prepare MLflow metadata\n",
    "# ------------------------------------\n",
    "input_example = X_test.iloc[[0]].to_dict(orient=\"records\")[0]  # sample row as dict\n",
    "signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "with mlflow.start_run(run_name=f\"{metric}_forecast_model\"):\n",
    "    mlflow.log_param(\"metric\", metric)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "print(f\"{metric}: R¬≤ = {r2:.3f}\")\n",
    "print(\"Model training complete with input example and signature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bfd396d-9bc9-4dd4-95c8-d1d23bb404e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# Retrieve run id: https://<workspace_url>/ml/experiments/<experiment_id>/models/<model_id>\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "run_id = '2e7a7a133c7848c69d1ea22814911b9e'\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "X_example = pd.DataFrame([{\n",
    "    \"lag_1\": 70.3,\n",
    "    \"lag_2\": 70.1,\n",
    "    \"lag_3\": 69.8,\n",
    "    \"lag_4\": 69.5,\n",
    "    \"lag_5\": 69.2\n",
    "}])\n",
    "\n",
    "y_pred = model.predict(X_example)\n",
    "print(f\"Predicted Temperature: {y_pred[0]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4929169482775243,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "notebook",
   "widgets": {
    "Endpoint": {
     "currentValue": "136.111.31.216:4840",
     "nuid": "59cba933-ffd9-40c9-9ae8-4ab18440c9ed",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "localhost:4840",
      "label": "OPC UA endpoint",
      "name": "Endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "localhost:4840",
      "label": "OPC UA endpoint",
      "name": "Endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
