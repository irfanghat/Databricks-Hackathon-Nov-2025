{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71aeac21-30cf-415d-b43e-ab156709ff56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install databricks-vectorsearch langchain==0.1.0 mlflow==2.10.0 databricks-sdk --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1bd7a4-24db-447b-ab36-2f2db4d78dbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99e93273-5e80-45f0-a00f-7246bb95f151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Industrial Automation RAG Chatbot\n",
    "#### Quick Setup with An Existing Vector Search Index\n",
    "\n",
    "**What this notebook does:**\n",
    "\n",
    "1. Connects an existing Vector Search index containing Technical documentation on OPC UA\n",
    "2. Creates a RAG chain with Databricks foundation models\n",
    "3. Tests the chatbot\n",
    "4. Registers the model to Unity Catalog\n",
    "5. Deploys as a REST API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aef7ad5-53ed-4bd3-838a-91850ed8b863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "VECTOR_SEARCH_ENDPOINT = \"opcua_manual_siemens_vector_search_endpoint\"\n",
    "VECTOR_SEARCH_INDEX = \"workspace.default.opcua_manual_index\"\n",
    "TEXT_COLUMN = \"text\"\n",
    "\n",
    "CATALOG_NAME = \"workspace\"\n",
    "SCHEMA_NAME = \"default\"\n",
    "MODEL_NAME = \"opc_ua_rag_agent\"\n",
    "ENDPOINT_NAME = \"opc_ua_rag_agent\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Foundation model options:\n",
    "# - databricks-dbrx-instruct ??\n",
    "# - databricks-meta-llama-3-1-70b-instruct\n",
    "# - databricks-mixtral-8x7b-instruct\n",
    "# --------------------------------------------------------------\n",
    "FOUNDATION_MODEL = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "EMBEDDING_MODEL = \"databricks-gte-large-en\"\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"Vector Search Index: {VECTOR_SEARCH_INDEX}\")\n",
    "print(f\"Foundation Model: {FOUNDATION_MODEL}\")\n",
    "\n",
    "\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from langchain.vectorstores import DatabricksVectorSearch\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "\n",
    "\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "\n",
    "print(f\"Connecting to index: {VECTOR_SEARCH_INDEX}...\")\n",
    "vs_index = vsc.get_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT,\n",
    "    index_name=VECTOR_SEARCH_INDEX\n",
    ")\n",
    "\n",
    "\n",
    "embedding_model = DatabricksEmbeddings(endpoint=EMBEDDING_MODEL)\n",
    "\n",
    "\n",
    "retriever = DatabricksVectorSearch(\n",
    "    vs_index,\n",
    "    text_column=TEXT_COLUMN,\n",
    "    embedding=embedding_model,\n",
    "    columns=[TEXT_COLUMN, \"page\"]\n",
    ").as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Successfully connected to Vector Search index!\")\n",
    "print(f\"Retriever configured to fetch top 3 most relevant chunks\")\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatDatabricks\n",
    "\n",
    "\n",
    "chat_model = ChatDatabricks(\n",
    "    endpoint=FOUNDATION_MODEL,\n",
    "    max_tokens=500,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(f\"Foundation model '{FOUNDATION_MODEL}' configured!\")\n",
    "print(f\"   Max tokens: 500\")\n",
    "print(f\"   Temperature: 0.1\")\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"You are an expert assistant for industrial automation systems, specializing in protocols and technologies including:\n",
    "- OPC UA (Open Platform Communications Unified Architecture)\n",
    "- Modbus TCP (Modbus over TCP/IP)\n",
    "- MQTT (Message Queuing Telemetry Transport)\n",
    "- Matter (IoT connectivity standard)\n",
    "- HART (Highway Addressable Remote Transducer Protocol)\n",
    "\n",
    "Your role is to provide accurate, technical answers based on the documentation provided.\n",
    "\n",
    "Use the following context from the documentation to answer the user's question:\n",
    "\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Provide clear, technical answers with specific details\n",
    "- If you cannot find the answer in the context, say \"I don't have information about that in the documentation.\"\n",
    "- Do not make up or infer information not present in the context\n",
    "- When discussing protocols, mention their key characteristics\n",
    "- Include relevant technical specifications when available\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"Prompt template created...\")\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"RAG chain created successfully...\")\n",
    "print(\"\\nChain components:\")\n",
    "print(f\"  Retriever: {VECTOR_SEARCH_INDEX}\")\n",
    "print(f\"  LLM: {FOUNDATION_MODEL}\")\n",
    "print(f\"  Strategy: Stuff (All context in one prompt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ba5dcaf-769c-4013-a316-61836b650da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "test_questions = [\n",
    "    \"What is OPC UA and how does it work?\",\n",
    "    \"Explain the main features of Modbus TCP\",\n",
    "    \"How does MQTT differ from OPC UA?\",\n",
    "    \"What are the security features in these protocols?\"\n",
    "]\n",
    "\n",
    "print(\"Testing chatbot with sample questions...\\n\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(f\"Test {i}/{len(test_questions)}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    try:\n",
    "        result = rag_chain.invoke({\"query\": question})\n",
    "        \n",
    "        print(f\"Answer:\")\n",
    "        print(f\"{result['result']}\\n\")\n",
    "        \n",
    "        # ------------------------------------------------------\n",
    "        # Print sources\n",
    "        # ------------------------------------------------------\n",
    "        if result.get('source_documents'):\n",
    "            print(f\"Sources ({len(result['source_documents'])} documents):\")\n",
    "            for j, doc in enumerate(result['source_documents'], 1):\n",
    "                source = doc.metadata.get('page', 'Unknown source')\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                # Clean up the source path for better readability\n",
    "                # ------------------------------------------------------\n",
    "                if '/' in source:\n",
    "                    source = source.split('/')[-1]  # Get just the filename\n",
    "                preview = doc.page_content[:100].replace('\\n', ' ') + \"...\" if len(doc.page_content) > 100 else doc.page_content.replace('\\n', ' ')\n",
    "                print(f\"  {j}. {source}\")\n",
    "                print(f\"     {preview}\")\n",
    "        else:\n",
    "            print(f\"No source documents returned\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\\n\")\n",
    "        print(f\"Skipping to next question...\\n\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a5a737-9371-41bb-9589-e374aaa7b120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Sample questions related to OPC UA and Industrial Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb7e8a5-d667-4304-99ed-cd0ef007bfa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question = \"What is OPC UA?\" \n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "result = rag_chain({\"query\": question})\n",
    "\n",
    "print(f\"Answer:\\n{result['result']}\\n\")\n",
    "\n",
    "print(f\"\\nRetrieved from {len(result['source_documents'])} source(s):\")\n",
    "for i, doc in enumerate(result['source_documents'], 1):\n",
    "    print(f\"\\n{i}. Source: {doc.metadata.get('page', 'Unknown')}\")\n",
    "    print(f\"   Content preview: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc02358-e20e-4031-a390-47c175f4959b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question = \"How can I setup security policies correctly?\" \n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "result = rag_chain({\"query\": question})\n",
    "\n",
    "print(f\"Answer:\\n{result['result']}\\n\")\n",
    "\n",
    "print(f\"\\nRetrieved from {len(result['source_documents'])} source(s):\")\n",
    "for i, doc in enumerate(result['source_documents'], 1):\n",
    "    print(f\"\\n{i}. Source: {doc.metadata.get('page', 'Unknown')}\")\n",
    "    print(f\"   Content preview: {doc.page_content[:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rag_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
